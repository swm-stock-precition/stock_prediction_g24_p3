{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/k2rth1k/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "config = json.load(open(\"../configure.json\"))\n",
    "full_data_path = config['project_dir'] + config['sub_folders']['data_preprocess'] + config['full_data_pkls']\n",
    "nltk.download(\"popular\")\n",
    "stop_words = set(stopwords.words('english'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                                         article_content  \\\n12886  here are some things going on today in your wo...   \n13571  shutterstock photo\\nstocks indexes opened the ...   \n11837  by ryan vlastelica\\nto simply match the market...   \n13804  what happened shares of many optical networkin...   \n15737  by nigam arora\\nthe practical way to take adva...   \n...                                                  ...   \n1348   the biggest benefit from living are the lesson...   \n2553   apple stock price\\napple (nasdaq: aapl ) was v...   \n849    none of us has a crystal ball that shows us cl...   \n56164  let's talk about apple, inc. (nasdaq: aapl ). ...   \n61168  big trends: gartner iaas mq is down to 6 compa...   \n\n                                             word_tokens  trend  \\\n12886  [go, today, world, tech, bellweth, tech, march...      1   \n13571  [photo, stock, new, year, first, session, chee...      1   \n11837  [simpli, match, market, may, need, take, lot, ...      1   \n13804  [mani, optic, decemb, accord, data, p, global,...      1   \n15737  [practic, way, take, advantag, januari, effect...      1   \n...                                                  ...    ...   \n1348   [biggest, benefit, live, could, made, us, heal...      1   \n2553   [appl, stock, price, appl, conserv, project, h...      1   \n849    [none, us, crystal, ball, us, clear, economi, ...     -1   \n56164  [let, talk, appl, specif, let, talk, innov, ap...     -1   \n61168  [big, azur, oracl, grow, azur, explicit, broke...     -1   \n\n                                                features  \n12886  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n13571  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n11837  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n13804  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n15737  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n...                                                  ...  \n1348   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2553   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n849    [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, ...  \n56164  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n61168  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n\n[5677 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article_content</th>\n      <th>word_tokens</th>\n      <th>trend</th>\n      <th>features</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12886</th>\n      <td>here are some things going on today in your wo...</td>\n      <td>[go, today, world, tech, bellweth, tech, march...</td>\n      <td>1</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>13571</th>\n      <td>shutterstock photo\\nstocks indexes opened the ...</td>\n      <td>[photo, stock, new, year, first, session, chee...</td>\n      <td>1</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>11837</th>\n      <td>by ryan vlastelica\\nto simply match the market...</td>\n      <td>[simpli, match, market, may, need, take, lot, ...</td>\n      <td>1</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>13804</th>\n      <td>what happened shares of many optical networkin...</td>\n      <td>[mani, optic, decemb, accord, data, p, global,...</td>\n      <td>1</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>15737</th>\n      <td>by nigam arora\\nthe practical way to take adva...</td>\n      <td>[practic, way, take, advantag, januari, effect...</td>\n      <td>1</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1348</th>\n      <td>the biggest benefit from living are the lesson...</td>\n      <td>[biggest, benefit, live, could, made, us, heal...</td>\n      <td>1</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2553</th>\n      <td>apple stock price\\napple (nasdaq: aapl ) was v...</td>\n      <td>[appl, stock, price, appl, conserv, project, h...</td>\n      <td>1</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>849</th>\n      <td>none of us has a crystal ball that shows us cl...</td>\n      <td>[none, us, crystal, ball, us, clear, economi, ...</td>\n      <td>-1</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>56164</th>\n      <td>let's talk about apple, inc. (nasdaq: aapl ). ...</td>\n      <td>[let, talk, appl, specif, let, talk, innov, ap...</td>\n      <td>-1</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>61168</th>\n      <td>big trends: gartner iaas mq is down to 6 compa...</td>\n      <td>[big, azur, oracl, grow, azur, explicit, broke...</td>\n      <td>-1</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5677 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkls = os.listdir(full_data_path)\n",
    "for pkl in pkls:\n",
    "    data = pd.read_pickle(full_data_path + pkl, compression=\"infer\")\n",
    "    k = data\n",
    "    data.head()\n",
    "    corpus = []\n",
    "    name = pkl.split(\"_\")\n",
    "    tail = name[len(name) - 1]\n",
    "    time = tail.replace(\"data\", \"\").replace(\".pkl\", \"\")\n",
    "    for index, row in data.iterrows():\n",
    "        corpus.append(' '.join(row['word_tokens']))\n",
    "    for i in range(2, 4):\n",
    "        gram_vectorizer = CountVectorizer(max_df=0.9, min_df=0.01, stop_words=stop_words, ngram_range=(i, i))\n",
    "        data_features = gram_vectorizer.fit_transform(corpus)\n",
    "        features_array = data_features.toarray()\n",
    "        data['features'] = features_array.tolist()\n",
    "        data.head()\n",
    "        if \"amazon\" in pkl:\n",
    "            path = \"pkls/\" + 'amzn_' + time + '_' + str(i) + 'gram.pkl'\n",
    "            with open(path, 'wb') as f:\n",
    "                pickle.dump(data, f)\n",
    "        if \"apple\" in pkl:\n",
    "            path = \"pkls/\" + 'aapl_' + time + '_' + str(i) + 'gram.pkl'\n",
    "            with open(path, 'wb') as f:\n",
    "                pickle.dump(data, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}