{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "stop_words = stopwords.words('english')\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12886</th>\n",
       "      <td>here are some things going on today in your wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13571</th>\n",
       "      <td>shutterstock photo\\nstocks indexes opened the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11837</th>\n",
       "      <td>by ryan vlastelica\\nto simply match the market...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13804</th>\n",
       "      <td>what happened shares of many optical networkin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15737</th>\n",
       "      <td>by nigam arora\\nthe practical way to take adva...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "12886  here are some things going on today in your wo...       1\n",
       "13571  shutterstock photo\\nstocks indexes opened the ...       1\n",
       "11837  by ryan vlastelica\\nto simply match the market...       1\n",
       "13804  what happened shares of many optical networkin...       1\n",
       "15737  by nigam arora\\nthe practical way to take adva...       1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = pd.read_csv('train.csv')\n",
    "amzn_train = pd.read_pickle(\"amazon_data_for_training.pkl\", compression='infer')\n",
    "amzn_train.head()\n",
    "train = amzn_train[['article_content', 'trend']]\n",
    "train.columns = ['text', 'target']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5677, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train data into train and validation sets\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train.text.values, train.target.values,\n",
    "                                                        stratify = train.target.values,\n",
    "                                                        random_state = 42,\n",
    "                                                        test_size = 0.1,\n",
    "                                                        shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf vectorization\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "tfv.fit(list(x_train) + list(x_valid))\n",
    "xtrain_tfv = tfv.transform(x_train)\n",
    "xvalid_tfv = tfv.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')\n",
    "\n",
    "# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\n",
    "ctv.fit(list(x_train) + list(x_valid))\n",
    "xtrain_ctv =  ctv.transform(x_train) \n",
    "xvalid_ctv = ctv.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean k-fold accuracy: 0.7228426142974061 \n",
      "mean k-fold f1: 0.6311187333385699\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with tf-idf\n",
    "clf = LogisticRegression(C = 1.0)\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score),'f1' : make_scorer(f1_score)}\n",
    "scores = cross_validate(clf, xtrain_tfv, y_train, cv=5, scoring = scoring)\n",
    "acc = scores.get('test_accuracy')\n",
    "f1 = scores.get('test_f1')\n",
    "print(f'mean k-fold accuracy: {np.mean(acc)} \\nmean k-fold f1: {np.mean(f1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean k-fold accuracy: 0.7204921693363054 \n",
      "mean k-fold f1: 0.6869121162715618\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with n-gram\n",
    "clf = LogisticRegression(C = 1.0)\n",
    "scores = cross_validate(clf, xtrain_ctv, y_train, cv=5, scoring = scoring)\n",
    "acc = scores.get('test_accuracy')\n",
    "f1 = scores.get('test_f1')\n",
    "print(f'mean k-fold accuracy: {np.mean(acc)} \\nmean k-fold f1: {np.mean(f1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean k-fold accuracy: 0.6834993511982228 \n",
      "mean k-fold f1: 0.5024658467032534\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on tf-idf\n",
    "clf = MultinomialNB()\n",
    "scores = cross_validate(clf, xtrain_tfv, y_train, cv=5, scoring = scoring)\n",
    "acc = scores.get('test_accuracy')\n",
    "f1 = scores.get('test_f1')\n",
    "print(f'mean k-fold accuracy: {np.mean(acc)} \\nmean k-fold f1: {np.mean(f1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean k-fold accuracy: 0.7238241545930757 \n",
      "mean k-fold f1: 0.6860893079292215\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on n-gram\n",
    "clf = MultinomialNB()\n",
    "scores = cross_validate(clf, xtrain_ctv, y_train, cv=5, scoring = scoring)\n",
    "acc = scores.get('test_accuracy')\n",
    "f1 = scores.get('test_f1')\n",
    "print(f'mean k-fold accuracy: {np.mean(acc)} \\nmean k-fold f1: {np.mean(f1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [01:40, 21770.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2195884 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the GloVe vectors in a dictionary:\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('glove.840B.300d/glove.840B.300d.txt')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    try:\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    except:\n",
    "        pass\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function creates a normalized vector for the whole sentence\n",
    "def sent2vec(s):\n",
    "    words = str(s).lower()\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5109/5109 [00:42<00:00, 121.34it/s]\n",
      "100%|██████████| 568/568 [00:04<00:00, 127.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# create sentence vectors using the above function for training and validation set\n",
    "xtrain_glove = [sent2vec(x) for x in tqdm(x_train)]\n",
    "xvalid_glove = [sent2vec(x) for x in tqdm(x_valid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean k-fold accuracy: 0.5562721019069213 \n",
      "mean k-fold f1: 0.24653244807902813\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with GloVe\n",
    "clf = LogisticRegression(C = 1.0)\n",
    "scores = cross_validate(clf, xtrain_glove, y_train, cv=5, scoring = scoring)\n",
    "acc = scores.get('test_accuracy')\n",
    "f1 = scores.get('test_f1')\n",
    "print(f'mean k-fold accuracy: {np.mean(acc)} \\nmean k-fold f1: {np.mean(f1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a simple Naive Bayes on glove (failing due to negative values)\n",
    "# clf = MultinomialNB()\n",
    "# clf.fit(xtrain_glove, y_train)\n",
    "# predictions = clf.predict(xvalid_glove)\n",
    "# accuracy_score(predictions, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform pca on glove data\n",
    "pca = PCA(n_components = 10)\n",
    "pca.fit(xtrain_glove)\n",
    "xtrain_glove_pca = pca.transform(xtrain_glove)\n",
    "xvalid_glove_pca = pca.transform(xvalid_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean k-fold accuracy: 0.5515750453777905 \n",
      "mean k-fold f1: 0.14086919708197243\n"
     ]
    }
   ],
   "source": [
    "# logistic regression with GloVe\n",
    "clf = LogisticRegression(C = 1.0)\n",
    "scores = cross_validate(clf, xtrain_glove_pca, y_train, cv=5, scoring = scoring)\n",
    "acc = scores.get('test_accuracy')\n",
    "f1 = scores.get('test_f1')\n",
    "print(f'mean k-fold accuracy: {np.mean(acc)} \\nmean k-fold f1: {np.mean(f1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean k-fold accuracy: 0.574671238626802 \n",
      "mean k-fold f1: 0.29009922092286844\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple SVM to GloVe with PCA\n",
    "clf = SVC(C=1.0, probability=True) # since we need probabilities\n",
    "scores = cross_validate(clf, xtrain_glove_pca, y_train, cv=5, scoring = scoring)\n",
    "acc = scores.get('test_accuracy')\n",
    "f1 = scores.get('test_f1')\n",
    "print(f'mean k-fold accuracy: {np.mean(acc)} \\nmean k-fold f1: {np.mean(f1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a simple xgboost on tf-idf (taking too long)\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "scores = cross_validate(clf, xtrain_glove_pca, y_train, cv=5, scoring = scoring)\n",
    "acc = scores.get('test_accuracy')\n",
    "f1 = scores.get('test_f1')\n",
    "print(f'mean k-fold accuracy: {np.mean(acc)} \\nmean k-fold f1: {np.mean(f1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_train_data = pd.DataFrame({'features': xtrain_glove, 'trend': y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glove_train_data['features'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pkls/amzn_train_glove.pkl', 'wb') as f:\n",
    "    pickle.dump(xtrain_glove, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d31f39ef5af9480f4ff911f4f9ab4f1d96b92a145925a631887d474182141c79"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('asu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
